# Selbsttestfragen

Nachfolgende Fragen eigenen sich zur PrÃ¼fungsvorbereitung mittels **Active Recall** gedacht und eine ErgÃ¤nzung zu Karteikarten.

Offizielle Fragen sind mit ğŸ§  markiert. Probeklausurfragen mit einem ğŸ¦§. Fragen der University of Berkley mit ğŸ§‘â€ğŸš’. Eigene Fragen haben keine Markierung.

## Linear Regression

* Under which assumptions is the least squares objective from linear regression equivalent to a maximum likelihood objective?ğŸ¦§
* Give the formula for ridge regression and explain its components.
* Give the formula for LASSO and explain its components.
* Compare Multiple Linear Regression to LASSO. Why is it desirable to penalize a Linear Regression model?
* Why do errors of a linear regression model have to be normally distributed?

## Linear Classification

* Write down the objective of linear binary logistic regression. The samples are given by $$x_{i}$$ and the labels by $$c_{i} \in\{0,1\}$$. How is $$p\left(c_{i} \mid \boldsymbol{x}_{i}\right)$$ assumed to be distributed in binary logistic regression?ğŸ¦§

## Model Selection

* Why is it a bad idea to evaluate your algorithm on the training set? ğŸ§ 
* What is the difference between true and empirical risk? ğŸ§ 
* The true risk can be decomposed in which parts?ğŸ§ 
* How is the bias and the variance of a learning algorithm defined and how do they contribute to the true risk?ğŸ§ 
* What is the advantage/disadvantage of k-fold CV vs. the Hold-out method?ğŸ§ 
* Why does it make sense to penalize the norm of the weight vector?ğŸ§ 
* Which norm can we use and what are the different effects?
* What is the effect of early stopping?ğŸ§ 

## Nearest Neighbour Algorithms, Trees, and Forests

* _What we mean with non-parametric / instance-based machine learning algorithms?_ğŸ§ 
  * Non-parametric ML algorithms are algorithms, that do not learn a parametric model, but store all the training data and use the training data to make predictions.
  * Examples include the $$k$$-nearest neighbour algorithm and the Gaussian processes.
* _How does_ $$k$$_-Nearest neighbour works?ğŸ§ _
  * To classifiy a new input vector $$x$$, we examine the $$k$$closest training data points to $$x$$\(that lie within a hypersphere\). 
  * We assign the class that is most frequent among those neighbours to the query point $$x$$.
* _Why is it hard to use for high-dimensional data?ğŸ§ _
  * $$k$$-Nearest neighbour is built around a distant-based measure. However, in a very high-dimensional space, most points are equally far appart from each other.
  * So the neighbourhood becomes large.
* _How to search for nearest neighbours efficiently?ğŸ§ _
  * It's convient to use a KD-tree as the data structure. The KD tree is balanced and performs binary splits on the feature space.
  * Searching goes like this:
    * Find region containing $$\boldsymbol{x}$$. Navigate starting from the root node to the child node containing $$\boldsymbol{x}$$.
    * Save region point $$\boldsymbol{x}^{*} = \boldsymbol{x}_{0}$$ as current best.
    * Move up tree and recursively search regions interesecting hypersphere $$S\left(\boldsymbol{x},\left\|\boldsymbol{x}-\boldsymbol{x}^{*}\right\|\right)$$. 
    * Update $$\boldsymbol{x}^{*}$$ if new nearsest neighbour has been found.
* _What is a binary regression / decision tree?ğŸ§ _
  * A binary decision tree is a tree that performs a binary split at each node. The predictor space is segmented into smaller regions. 
  * In case of regression trees the predicted value at a node is the average response variable of all observations within this node.
* _What are useful splitting criterions?ğŸ§ _
  * **For regression trees:** 
    * Minimum residual sum of squares: $$\mathrm{RSS}=\sum_{\text {left }}\left(y_{i}-\bar{y}_{L}\right)^{2}+\sum_{\text {right }}\left(y_{i}-\bar{y}_{R}\right)^{2}$$ 
  * **For classification trees:**
    * Information gain / Minimum entropy: $$N_{L} H\left(p_{\mathrm{L}}\right)+N_{R} H\left(p_{\mathrm{R}}\right)$$ 
* _How can we influence the model complexity of a tree?_ğŸ§ 
  * One can limit the depth of the tree or limit the minimum number of samples that must be present within one node.
  * Another way is to apply pruning to a decision tree, which refers to cutting back a fully grown tree.
* _Why is it useful to use multiple trees and randomization?_ğŸ§ 
  * Decision Trees are prone to overfitting. That's why we should learn several trees to increase variability.
  * By randomizing the features and combining the trees \(random forest\) or learning several trees on bootstrap samples \(bagging\) one can prevent trees from overfitting.
* Name at least two advantages and two disadvantages of decision trees. ğŸ¦§
  * **Advantages**:
    * Easy to interpret \(if they are small\)
    * Computionally efficient. They are quick to fit, even for large problems.
  * **Disadvantage**:
    * Other ML methods such as NN achieve a better accuracy.
    * Suffer from instability, if we change the data, ever-so-slightly trees can change a lot. 
* _Which data structure is usually used to efficiently implement k-Nearest Neighbours? Name the main steps in building that data structure._ğŸ¦§
  * KD-Trees are commonly used.
  * Building the tree:
    * choose dimension \(e. g. longest hyper-rectangle\)
    * Choose median as pivot
    * Split node according tho chosen pivot and dimension.

## Clustering

* _How is the clustering problem defined?ğŸ§ _
  * Clustering tries to find a natural grouping within the data.
  * One tries to maximize the intra-cluster similarity and minimize the inter-cluster similarity.
* _Why is it called 'unsupervised'?ğŸ§ _
  * It's called unsupervised, as the data is unlabeled. There is no supervisor, that tells us in advance to which cluster a training data point belongs. Hence, unsupervised. The structure is actually learned from the data. 
* _How do hierarchical clustering methods work?_ ğŸ§ 
  * **Init-phase:** Each of the $$n$$samples becomes a cluster itself
  * **Iterate-phase:** 
    1. Find closest clusters and merge them
    2. Proceed until we have a single cluster
* _What is the rule of the cluster-2-cluster distance and which distances can we use?_ğŸ§ 
  * So called cluster linkage types define the distance between two clusters. Commonly used are
    * Single linkage
    * Complete linkage
    * Average linkage
    * Centroid linkage
* _How does the_ $$k$$_-mean algorithm work? What are the two main steps?_ğŸ§ 
  * The two main steps are the **assigment** and **adjustment step**.
  * **Assignment step:** 
    * Assign each sample to its closest centroid $$z_{n}=\arg \min_{k}\left\|\boldsymbol{c}_{k}-\boldsymbol{x}_{n}\right\|^{2}$$ 
  * **Adjustment Step:**
    * Adjust the centroids to be the means of the samples assigned to them: $$c_{k}=\frac{1}{\left|X_{k}\right|} \sum_{\boldsymbol{x}_{i} \in X_{k}} \boldsymbol{x}_{i}, \quad X_{k}=\left\{\boldsymbol{x}_{n} \mid z_{n}=k\right\}$$ 
* _Why does the algorithm converge? What is it minimizing?_ğŸ§ 
  * $$k$$-means minimizes the Sum of Squared Distances \(SSD\). By checking, if a cluster centeroids exists, that is closer to a point than its current cluster centroid the SSD is reduced. If no closer custer centre exists and the SSD remains constant.
  * SSD is defined as $$\operatorname{SSD}(C ; \mathcal{D})=\sum_{i=1}^{n} d\left(\boldsymbol{x}_{i}, c\left(\boldsymbol{x}_{i}\right)\right)^{2} $$ 
* _Does_ $$k$$_-means find a global minimum of the objective?ğŸ§ _
  * No, generally it doesn't. Finding a global minimum is a NP-hard problem. One would have to check all assignments to find the global best solution.
  * More over, the result of $$k$$-means is heavily dependent on the initialisation.

## Dimensionality Reduction

* What does dimensionality reduction mean?ğŸ§ 
* What is PCA? ğŸ§ 
* What are three things that it does?ğŸ§ 
* What are the roles of the Eigenvectors and Eigenvalues in PCA?ğŸ§ 
* Can you describe applications of PCA?ğŸ§ 
* Why should each dimension have a unit variance / be normalized?

## Density Estimation and Expectation Maximization

* What are parametric methods and how to obtain their parameters?ğŸ§ 
* How many parameters have non-parametric methods?ğŸ§ 
* What are mixture models?ğŸ§ 
* Should gradient methods be used for training mixture models?ğŸ§ 
* How does the EM algorithm work?ğŸ§ 
* What is the biggest problem of mixture models?ğŸ§ 
* How does EM decomposes the marginal likelihood?ğŸ§ 
* Why does EM always improve the lower bound?ğŸ§ 
* Why does EM always improve the marginal likelihood?ğŸ§ 
* Why can we optimize each mixture component independently with EM?ğŸ§ 
* Why do we need sampling for continuous latent variables?ğŸ§ 

## Kernel methods

* What is the definition of a kernel and its relation to an underlying feature space?ğŸ§ 
* Why are kernels more powerful than traditional feature-based methods?ğŸ§ 
* What do we mean by the kernel trick?ğŸ§ 
* How do we apply the kernel trick to ridge regression?ğŸ§ 
* Study the kernel properties, where is symmetry relevant? Where and why is positive definiteness of matrix important?
* What is the impact of changing $$\sigma$$ in a RBF kernel?
* What is the actual gain from using polynomial kernels?

## SVMs

* Why is it good to use a maximum margin objective for classification?ğŸ§ 
* How can we define the margin as an optimization problem?
* What are slack variables and how can they be used to get a 'soft' margin?ğŸ§ 
* How is the hinge loss defined?ğŸ§ 
* What is the relation between the slack variables and the hinge loss?ğŸ§ 
* What are advantages and disadvantages in comparison to logistic regression?ğŸ§ 
* What is the difference between gradients and sub-gradients?ğŸ§ 
* First, explain the intuition behind slack-variables in support vector machine training. Second, for a single data-point $$\left(\boldsymbol{x}_{i}, c_{i}\right)$$ the margin condition with slack variable $$\xi_{i}$$ is given as

  $$
  c_{i}\left(\boldsymbol{w}^{T} \boldsymbol{x}_{i}+b\right) \geq 1-\xi_{i}
  $$

  * Assuming $$0 \leq \xi_{i} \leq 1$$, is $$\boldsymbol{x}_{i}$$ classified correctly?
  * Assuming $$\xi_{i}>1$$, is $$x_{i}$$ classified correctly?ğŸ¦§

## Bayesian Learning

* What are the two basic steps behind Bayesian Learning?ğŸ§ 
* Why is Bayesian Learning more robust against overfitting?ğŸ§ 
* What happens with the posterior if we add more data to the training set?ğŸ§ 
* What is completing the square and how does it work?ğŸ§ 
* For which 2 cases can Bayesian Learning be solved in closed form?ğŸ§ 
* Which approximations can we use if no closed form is available?
* How can we derive Bayesian Linear regression?ğŸ§ 
* What is the advantage of Bayesian Linear Regression over Ridge regression? What is the conceptual difference?ğŸ§ 
* What is the major advantage of Gaussian processes over kernel ridge regression?ğŸ§ 
* Why are GPs a Bayesian approach?ğŸ§ 
* What principle allowed deriving GPs from a Bayesian regression point of view?ğŸ§ 
* Gaussian Processes\(GP\) are also referred to as a "Bayesian Kernel Regression" approach. Why? ğŸ¦§

## Neural Nets

* How does logistic regression relate to neural networks?ğŸ§ 
* What kind of functions can single-layer neural networks learn?ğŸ§ 
* Why do we need non-linear activation functions?ğŸ§ 
* What activation functions can we use and what are the advantages/disadvantages of those?ğŸ§ 
* What output layer and loss function to use given the task \(regression, classification\)?ğŸ§ 
* Why not use a sigmoid activation function?ğŸ§ 
* Derive the equations for forward and backpropagation for a simple network.ğŸ§ 
* What is mini-batch gradient descent? Why use it instead of stochastic gradient descent or full gradient descent?ğŸ§ 
* Why neural networks can overfit and what are the options to prevent it?ğŸ§ 
* Why is the initialization of the network important?ğŸ§ 
* What can you read from the loss-curves during training \(validation and training loss\)?ğŸ§ 
* How can we accelerate gradient descent?ğŸ§ 
* How does Adam work?ğŸ§ 
* What is the key idea behind second-order optimization methods? What are their benefits? Why are second-order optimization methods usually not applicable for Deep Neural Networks? ğŸ¦§
* _Explain why sigmoid activation results tend to be almost_ $$0$$ _or_ $$1$$?
* Adding more hidden layers will solve the vanishing gradient problem for a two-layer neural network. ğŸ§‘â€ğŸš’
* xxx suffer\(s\) from the vanishing gradient problem. Circle all that apply and JUSTIFY YOUR ANSWER. ğŸ§‘â€ğŸš’
* Adding L2-regularization will help with vanishing gradients ğŸ§‘â€ğŸš’
* Early stopping, cross-validation, and network pruning are techniques to prevent overfitting of Neural Nets. Explain them. 
* For a fully-connected deep network with one hidden layer, increasing the number of hidden units should have what effect on bias and variance? ğŸ§‘â€ğŸš’
* What is the problem of Neural nets with many parameters?
* Explain what network pruning is.
* Explain how early stopping works with Neural Nets.

## CNNs

* Why are fully connected networks for images a bad idea and why do we need images?ğŸ§ 
* What are the key components of a CNN?ğŸ§ 
* What hyper-parameters can we set for a convolutional layer and what is their meaning?ğŸ§ 
* What hyper-parameters can we set for a pooling layer and what is their meaning?ğŸ§ 
* How can we compute dimensionality of the output of a convolutional layer?ğŸ§ 
* Describe basic properties of 'AlexNet' and 'VCG'.ğŸ§ 
* What is the main idea of 'ResNet' to make it very deep?ğŸ§ 
* Why is it not feasible to use a fully connected layer for images? How do convolutional neural networks solve this problem and which property of an image do they exploit?ğŸ¦§
* How do LSTMs actually avoid the vanishing gradient problem?

## General

* What is the difference between AI and ML?
* What are the hyperparameters for choosing the model complexity for each of the following algorithms. Name at least one hyperparameter for every algorithm.
  * Neural Networks
  * Support Vector Machines
  * Gaussian Processes
  * Decision Trees? ğŸ¦§
* You are given the following optimization problem:

  $$
  \begin{aligned}
  &\underset{a}{\operatorname{argmax}} a^{2} h \\
  &\qquad \text { s.t. } S_{\max } \geq 2 a^{2}+4 a h
  \end{aligned}
  $$

  Write down the Lagrangian. Derive the optimal value for $$a$$ depending on your lagrangian multiplier. ğŸ¦§

