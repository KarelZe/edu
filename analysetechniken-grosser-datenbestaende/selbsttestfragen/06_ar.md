# Association Rules

_Was sind Association Rules?_
* $A \Rightarrow B\[s, c\]$, $A$ und $B$ sind Itemsets. $s$ steht für Support und $c$ für Confidence.

_Wie findet man sie?_
* Typischerweise mit Apriori-Algorithmus. Dieser umfasst:
  1. Erzeugung der einelementigen Frequent Itemsets
  2. Erzeugen der $k$-elementigen Frequent Itemsets
  3. Aus Frequent Itemsets Association Rules ableiten
* Alternativ: Verbesserter Apriori-Algorithmus / FP-Trees

_Wie überprüft man rasch für viele Transaktionen, welche Kandidaten sie enthalten?_
* Verwendung von FP-Trees anstelle von Apriori oder Erweiterungen von Apriori z. B. Apriori mit Hashmap \(Folie 31\)

_Geben Sie ein Beispiel für eine Association Rule mit hohem/niedrigem Support und hoher/niedriger Confidence._
* hoher Support, aber niedrige confidence:
  * 30% der Kunden kaufen Bier und Schnaps. 100% der Kunden kaufen Bier.
* hoher Support, aber hohe confidence:
  * Viele Kunden kaufen Bier und Schnaps. Wenn Bier in Transaktion ist, ist auch Schnaps häufig.
* niedriger Support, hohe confidence:
  * Wenige Transaktionen enthalten Bier und Schnaps. Wenn Bier gekauft wird, dann wird auch immer Schnaps gekauft.
* niedriger Support, niedrige confidence:
  * Schnaps und Bier sind selten gemeinsam in Transaktion enthalten, Wenn Schnaps vorkommt, dann kommt selten Bier vor.

_Was sind multi-dimensionale Association Rules?_
* Zusammenhänge von Attributwerten aus relationalem Datenbestand.

_Was sind Multi-Level Association Rules?_
  * Menge von Regeln auf unterschiedlichen Hierarchieebenen, aber gleiches Abstraktionsniveau z. B. Entenleberpastete und Roter Tee. Eine Ebene ist abstrakter als die andere.

_Was sind Level-Crossing Rules?_
  * Level-Crossing → Verknüpfung verschiedener Hierarchieebene z. B. Entenleberpastete und Milch

_Was sind Multi-Level Association Rules, und wie findet man sie?_
  * Man ordnet jedes Produkt des Warenkorbs einer Hierarchie s. g. Levels zu. Einzelne Hierarchiestufen geben dann z. B. Zugehörigkeit an z. B. Feingebäck / Brot o. Ä. Die Levels werden dann in der Transaktionstabelle mit eincodiert. Für Itemsets der unterschiedlichen Level wird dann der Mindest-Support bestimmt.
    * Naive Implementierung: Durchlaufen Level nach Level
    * Optimierte Implementierung: Wird ein Item angetroffen werden mehrere Zähler für jedes Level inkrementiert.

_Wann hört Apriori-Algorithmus auf?_
  * Algorithmus terminiert spätestens nach der Runde, nach der k die Größe des größten Itemsets angibt.

_Was sagt Confidence aus?_ 
  * Maß für die Verlässlichkeit einer Regel. Anteil der Transaktionen in A, die auch in B enthalten sind, Schätzung der bedingten Wahrscheinlichkeit von $$A \Rightarrow B$$. 

_Was sagt Support aus?_ 
  * Maß für die Häufigkeit einer Item-Menge. Anzahl der Transaktionen, die $$A$$ und $$B$$ enthalten. Häufigkeit der Regel in Menge der Transaktionen. Hoher Wert – Regel beschreibt Großteil des Datenbestands.

_Kein Prune-Schritt bei $$k=2$$, warum?_
  * Kandidatenmengen entspricht bereits $$L_1$$.
